# -*- coding: utf-8 -*-
"""
RAG æ ¸å¿ƒå¼•æ“èˆ‡ ETL æµç¨‹ (RAG Core Engine & ETL Pipeline)

æ­¤æ¨¡çµ„è² è²¬è™•ç† RAG ç³»çµ±çš„å¾Œç«¯é‚è¼¯ï¼ŒåŒ…å«ï¼š
1. è³‡æ–™æ“·å– (Data Ingestion): ä½¿ç”¨ LlamaParse è§£æ PDF å¹´å ±ã€‚
2. ç´¢å¼•å»ºæ§‹ (Indexing): å»ºç«‹å‘é‡ç´¢å¼• (Vector Index) ä¸¦æŒä¹…åŒ–å„²å­˜ã€‚
3. æŸ¥è©¢å¼•æ“å·¥å»  (Query Engine Factory): å°è£æ··åˆæª¢ç´¢ (Hybrid Search) çš„åˆå§‹åŒ–é‚è¼¯ã€‚

ç”¨é€”:
- ä½œç‚º `main` åŸ·è¡Œæ™‚ï¼ŒåŸ·è¡Œ ETL æµç¨‹ä¸¦ç”Ÿæˆç´¢å¼•ã€‚
- ä½œç‚ºæ¨¡çµ„è¢« `app.py` åŒ¯å…¥æ™‚ï¼Œæä¾›æŸ¥è©¢å¼•æ“å»ºæ§‹åŠŸèƒ½ã€‚
"""

import os
import sys
import shutil
import nest_asyncio

# --- LlamaIndex æ ¸å¿ƒçµ„ä»¶ (Core Components) ---
from llama_index.core import (
    VectorStoreIndex, 
    SimpleDirectoryReader, 
    StorageContext, 
    load_index_from_storage, 
    Settings, 
    PromptTemplate
)
from llama_index.core.retrievers import VectorIndexRetriever, BaseRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.schema import NodeWithScore

# --- Google Gemini æ¨¡å‹æ•´åˆ (Check Gemini Integration) ---
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding

# --- è³‡æ–™è§£æå™¨ (Advanced Parsing) ---
from llama_parse import LlamaParse

# --- é—œéµå­—æª¢ç´¢ (Keyword Search) ---
from llama_index.retrievers.bm25 import BM25Retriever

# è§£æ±ºç•°æ­¥ç’°å¢ƒä¸‹çš„ Event Loop å•é¡Œ
nest_asyncio.apply()

# ================= å…¨åŸŸé…ç½® (Global Configuration) =================

# 1. API Keys (å»ºè­°ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ç®¡ç†ï¼Œé¿å… Hardcode)
# os.environ["LLAMA_CLOUD_API_KEY"] = "llx-..." 
# os.environ["GOOGLE_API_KEY"] = "AIza..."

# 2. æª”æ¡ˆè·¯å¾‘é…ç½® (File Path Configuration)
# ä½¿ç”¨åŸå§‹å­—ä¸² (Raw String) é˜²æ­¢ Windows è·¯å¾‘è½‰ç¾©å•é¡Œ
PDF_PATH = "TSMC_2024 Annual Report-C.pdf"
PERSIST_DIR = "./storage"

# 3. ç´¢å¼•é‡å»ºç­–ç•¥ (Re-indexing Strategy)
# FORCE_RELOAD = True:  å¼·åˆ¶æ¸…é™¤èˆŠç´¢å¼•ï¼Œé‡æ–°åŸ·è¡Œ ETL (æ¶ˆè€— LlamaCloud é¡åº¦)
# FORCE_RELOAD = False: è‹¥ç´¢å¼•å­˜åœ¨å‰‡ç›´æ¥è®€å– (Cache Hit)ï¼Œç¯€çœæˆæœ¬èˆ‡æ™‚é–“
# å»ºè­°é–‹ç™¼éšæ®µè¨­ç‚º Trueï¼Œéƒ¨ç½²å¾Œè¨­ç‚º False
FORCE_RELOAD = True 

# =================================================================

def init_settings():
    """
    åˆå§‹åŒ– LlamaIndex å…¨åŸŸè¨­å®š (Global Settings Initialization)ã€‚
    
    é…ç½®é è¨­çš„ LLM èˆ‡ Embedding æ¨¡å‹ï¼Œä»¥åŠ Chunking ç­–ç•¥ã€‚
    æ­¤å‡½æ•¸æ‡‰åœ¨ç³»çµ±å•Ÿå‹•æ™‚æœ€å…ˆè¢«èª¿ç”¨ã€‚
    """
    
    # [Model Configuration] ä½¿ç”¨ Google Gemini 2.5 Flash
    # å„ªå‹¢ï¼šé€Ÿåº¦å¿«ã€Context Window å¤§çš„è¼•é‡ç´šæ¨¡å‹
    # æ³¨æ„ï¼šè‹¥é‡ Rate Limit (429)ï¼Œå¯é™ç´šè‡³ "models/gemini-1.5-flash"
    Settings.llm = Gemini(model="models/gemini-2.5-flash")
    
    # [Embedding Configuration] ä½¿ç”¨å¤šèªè¨€æ–‡å­—åµŒå…¥æ¨¡å‹
    # å¿…é ˆæŒ‡å®š api_keyï¼Œä»¥ç¢ºä¿èˆ‡ LLM åˆ†é–‹è¨ˆè²»æˆ–ç®¡ç†
    Settings.embed_model = GeminiEmbedding(
        model_name="models/text-embedding-004",
        api_key=os.environ.get("GOOGLE_API_KEY")
    )
    
    # [Chunking Strategy] é‡å°å¹´å ±é•·æ–‡æœ¬å„ªåŒ–
    # chunk_size: 2048 Tokens (æ¶µè“‹æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼Œå¦‚é•·è¡¨æ ¼)
    # chunk_overlap: 200 Tokens (ä¿æŒèªæ„é€£è²«æ€§)
    Settings.chunk_size = 2048
    Settings.chunk_overlap = 200
    Settings.embed_batch_size = 10 

def get_index():
    """
    ç²å–å‘é‡ç´¢å¼• (Index Retrieval Strategy)ã€‚
    
    å¯¦ç¾ã€Œè®€å¯«åˆ†é›¢ã€é‚è¼¯ï¼š
    1. è‹¥ FORCE_RELOAD ç‚º Trueï¼Œå‰‡åˆªé™¤èˆŠç´¢å¼•ã€‚
    2. è‹¥ç´¢å¼•å­˜åœ¨ï¼Œç›´æ¥å¾ç£ç¢Ÿè¼‰å…¥ (Load from Disk)ã€‚
    3. è‹¥ç´¢å¼•ä¸å­˜åœ¨ï¼ŒåŸ·è¡Œå®Œæ•´ ETL æµç¨‹ï¼šè§£æ -> å‘é‡åŒ– -> å„²å­˜ã€‚
    
    Returns:
        VectorStoreIndex: åˆå§‹åŒ–å®Œæˆçš„å‘é‡ç´¢å¼•ç‰©ä»¶ã€‚
    """
    
    # è™•ç†å¼·åˆ¶é‡è·‘é‚è¼¯ (Force Reload Logic)
    if FORCE_RELOAD and os.path.exists(PERSIST_DIR):
        print(f"ğŸ§¹ [System] FORCE_RELOAD=Trueï¼Œæ¸…é™¤èˆŠç´¢å¼•ç›®éŒ„ï¼š{PERSIST_DIR}...")
        shutil.rmtree(PERSIST_DIR)

    # --- ç­–ç•¥ A: å¿«å–å‘½ä¸­ (Cache Hit) ---
    if os.path.exists(PERSIST_DIR):
        print(f"ğŸ“‚ [Storage] ç™¼ç¾ç¾æœ‰ç´¢å¼• ({PERSIST_DIR})ï¼Œç›´æ¥è¼‰å…¥...")
        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)
        index = load_index_from_storage(storage_context)
        return index

    # --- ç­–ç•¥ B: å†·å•Ÿå‹• (Cold Start / ETL) ---
    else:
        print("ğŸš€ [ETL] é–‹å§‹åŸ·è¡Œ LlamaParse è§£æèˆ‡å‘é‡åŒ–æµç¨‹...")
        
        # é…ç½® LlamaParse (Advanced PDF Parsing)
        # é‡å°ç¹é«”ä¸­æ–‡å¹´å ±å„ªåŒ–ï¼Œæä¾›ç‰¹å®šçš„ Prompt è™•ç†è·¨é è¡¨æ ¼
        parser = LlamaParse(
            result_type="markdown",
            verbose=True,
            language="ch_tra",
            parsing_instruction="""
            é€™æ˜¯ä¸€ä»½å¹´å ±ã€‚è«‹å°‡å…¶è§£æç‚ºæ¨™æº– Markdownã€‚
            é‡è¦è¦å‰‡ï¼š
            1. é‡åˆ°è·¨é çš„è¡¨æ ¼ï¼ˆå¦‚è‘£äº‹æœƒæˆå“¡åå–®ã€è²¡å‹™å ±è¡¨ï¼‰ï¼Œè«‹ç›¡é‡å°‡å…¶åˆä½µç‚ºä¸€å€‹å®Œæ•´çš„ Markdown è¡¨æ ¼ã€‚
            2. çµ•å°ä¸è¦éºæ¼è¡¨æ ¼ä¸­çš„ä»»ä½•ä¸€åˆ—ï¼ˆRowï¼‰æ•¸æ“šæˆ–æ•¸å­—ã€‚
            3. ä¿ç•™å°é¢ä¸Šçš„é—œéµè³‡è¨Šï¼ˆè‚¡ç¥¨ä»£è™Ÿã€åˆŠå°æ—¥æœŸï¼‰ã€‚
            """
        )
        
        file_extractor = {".pdf": parser}
        
        # æª”æ¡ˆå®Œæ•´æ€§æª¢æŸ¥
        if not os.path.exists(PDF_PATH):
            print(f"âŒ [Error] æ‰¾ä¸åˆ°ç›®æ¨™æª”æ¡ˆï¼š{PDF_PATH}")
            sys.exit(1)

        print(f"ğŸ“„ [Ingestion] è®€å–æª”æ¡ˆï¼š{PDF_PATH}")
        documents = SimpleDirectoryReader(
            input_files=[PDF_PATH],
            file_extractor=file_extractor
        ).load_data()
        
        # è§£æçµæœæŠ½æ¨£æª¢æŸ¥ (Sanity Check)
        print("\n--- LlamaParse è§£æé è¦½ (Sampling) ---")
        preview_text = documents[min(3, len(documents)-1)].text[:500] 
        print(preview_text)
        print("--------------------------------------\n")

        # å»ºç«‹å‘é‡ç´¢å¼• (Indexing)
        print("âš¡ [Vector Store] æ­£åœ¨å»ºç«‹ Vector Index (Chunk Size: 2048)...")
        index = VectorStoreIndex.from_documents(documents)
        
        # æŒä¹…åŒ–å„²å­˜ (Persistence)
        print(f"ğŸ’¾ [Storage] å„²å­˜ç´¢å¼•è‡³ {PERSIST_DIR}...")
        index.storage_context.persist(persist_dir=PERSIST_DIR)
        
        return index

# è‡ªå®šç¾©æ··åˆæª¢ç´¢å™¨ (Custom Hybrid Retriever)
# ç¹¼æ‰¿ BaseRetriever ä»¥æ•´åˆè‡³ LlamaIndex æµç¨‹
class CustomHybridRetriever(BaseRetriever):
    def __init__(self, vector_retriever, bm25_retriever):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        super().__init__()

    def _retrieve(self, query_bundle):
        # 1. åŸ·è¡Œå‘é‡æª¢ç´¢ (Vector Search)
        vec_nodes = self.vector_retriever.retrieve(query_bundle)
        # 2. åŸ·è¡Œé—œéµå­—æª¢ç´¢ (BM25 Search)
        bm25_nodes = self.bm25_retriever.retrieve(query_bundle)
        
        # 3. çµæœèåˆ (Result Fusion)
        # ä½¿ç”¨ Map çµæ§‹å»é‡ï¼Œå„ªå…ˆä¿ç•™å‘é‡æª¢ç´¢çš„åˆ†æ•¸èˆ‡ç¯€é»
        all_nodes = {}
        for node in vec_nodes:
            all_nodes[node.node.node_id] = node
        for node in bm25_nodes:
            if node.node.node_id not in all_nodes:
                all_nodes[node.node.node_id] = node
        
        # å›å‚³èåˆå¾Œçš„ Top-20 çµæœ
        combined_list = list(all_nodes.values())
        return combined_list[:20] 

def create_hybrid_query_engine(index):
    """
    å·¥å» æ¨¡å¼ (Factory Pattern) å»ºç«‹æ··åˆæª¢ç´¢æŸ¥è©¢å¼•æ“ã€‚
    
    Args:
        index (VectorStoreIndex): å·²è¼‰å…¥çš„å‘é‡ç´¢å¼•ã€‚
        
    Returns:
        RetrieverQueryEngine: é…ç½®å®Œæˆçš„æŸ¥è©¢å¼•æ“ã€‚
    """
    print("ğŸ”§ [Factory] åˆå§‹åŒ–æ··åˆæª¢ç´¢å™¨ (Custom Hybrid)...")
    
    # å¯¦ä½œæª¢ç´¢å™¨å…ƒä»¶
    vector_retriever = VectorIndexRetriever(
        index=index,
        similarity_top_k=10
    )

    bm25_retriever = BM25Retriever.from_defaults(
        docstore=index.docstore,
        similarity_top_k=10
    )

    # çµ„åˆ
    retriever = CustomHybridRetriever(vector_retriever, bm25_retriever)

    # å®šç¾©ç³»çµ±æç¤ºè© (System Prompt)
    # å¼·èª¿ä¾†æºä¾æ“šèˆ‡å›æ‡‰èªè¨€
    qa_prompt_str = (
        "ä»¥ä¸‹æ˜¯åƒè€ƒæ–‡ä»¶å…§å®¹ï¼š\n"
        "---------------------\n"
        "{context_str}\n"
        "---------------------\n"
        "è«‹åƒ…æ ¹æ“šä¸Šè¿°åƒè€ƒæ–‡ä»¶å…§å®¹ï¼Œå›ç­”ä½¿ç”¨è€…çš„å•é¡Œ: {query_str}\n"
        "åš´æ ¼ç¦æ­¢ç·¨é€ æ–‡ä»¶ä¸­æœªæåŠçš„äººåã€æ•¸å­—æˆ–è·ç¨±ã€‚\n"
        "å¦‚æœåƒè€ƒæ–‡ä»¶ä¸­æ²’æœ‰å®Œæ•´çš„åå–®æˆ–æ•¸æ“šï¼Œè«‹å›ç­”ã€Œæ–‡ä»¶ä¸­åƒ…æåŠéƒ¨åˆ†å…§å®¹ã€ï¼Œä¸¦åˆ—å‡ºä½ æœ‰çœ‹åˆ°çš„å³å¯ã€‚\n"
        "è«‹å‹™å¿…ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€å›ç­”ã€‚\n"
    )
    chinese_qa_prompt = PromptTemplate(qa_prompt_str)

    # å»ºæ§‹å¼•æ“
    query_engine = RetrieverQueryEngine.from_args(
        retriever=retriever,
        text_qa_template=chinese_qa_prompt
    )
    
    return query_engine

# ================= ç¨‹å¼å…¥å£ (Modules Entry Point) =================

if __name__ == "__main__":
    try:
        # 1. ç’°å¢ƒåˆå§‹åŒ– (Bootstrap)
        init_settings()
        
        # 2. æº–å‚™ç´¢å¼• (Prepare Index)
        index = get_index()
        
        # 3. å»ºç«‹å¼•æ“ (Build Engine)
        query_engine = create_hybrid_query_engine(index)

        print("\n==================================================")
        print(f"ğŸ¤– RAG ç³»çµ±å·²å•Ÿå‹• (Model: Gemini 2.5 Flash)")
        print(f"ğŸ“„ ç›®æ¨™æª”æ¡ˆ: {os.path.basename(PDF_PATH)}")
        print("ğŸ’¡ æç¤ºï¼šè¼¸å…¥ 'q' é›¢é–‹")
        print("==================================================\n")

        # 4. äº’å‹•å¼ REPL è¿´åœˆ (Interactive Loop)
        while True:
            user_input = input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ").strip()
            
            if user_input.lower() in ['q', 'exit', 'quit', 'é›¢é–‹']:
                print("ğŸ‘‹ ç¨‹å¼çµæŸ (Terminated)")
                break
            
            if not user_input:
                continue

            print("ğŸ¤– AI æ­£åœ¨æ¨è«–ä¸­ (Inference)...")
            response = query_engine.query(user_input)
            
            print(f"\nğŸ’¬ å›ç­”:\n{response}")
            
            # ä¾†æºå¯è§£é‡‹æ€§ (Explainability)
            print("\nğŸ•µï¸ [ä¾†æºè¿½è¹¤] åƒè€ƒäº†ä»¥ä¸‹ç‰‡æ®µï¼š")
            for node in response.source_nodes:
                score = f"{node.score:.2f}" if node.score is not None else "Hybrid"
                # é è¦½å…§å®¹
                preview = node.node.get_text()[:60].replace('\n', ' ')
                print(f"   - [åˆ†æ•¸ {score}] {preview}...")
            print("-" * 50)

    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ (Unexpected Error): {e}")
        import traceback
        traceback.print_exc()