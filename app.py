# -*- coding: utf-8 -*-
"""
æ‡‰ç”¨ç¨‹å¼å…¥å£é» (Entry Point)
æ­¤æ¨¡çµ„ä½¿ç”¨ Streamlit æ§‹å»º RAG (Retrieval-Augmented Generation) ç³»çµ±çš„å‰ç«¯ä»‹é¢ã€‚
å®ƒæ•´åˆäº† Google Gemini æ¨¡å‹èˆ‡æ··åˆæª¢ç´¢ç­–ç•¥ (Hybrid Search)ï¼Œæä¾›é‡å°å°ç©é›»å¹´å ±çš„å•ç­”æœå‹™ã€‚

ä¸»è¦åŠŸèƒ½:
1. æä¾›ä½¿ç”¨è€…ä»‹é¢ï¼Œç”¨æ–¼è¼¸å…¥ Google API Key èˆ‡æŸ¥è©¢å•é¡Œã€‚
2. å¯¦ä½œ Singleton æ¨¡å¼è¼‰å…¥ RAG å¼•æ“ï¼Œé¿å…é‡è¤‡åˆå§‹åŒ–è³‡æºã€‚
3. å±•ç¤ºæª¢ç´¢ä¾†æº (Source Nodes) èˆ‡ä¿¡å¿ƒåˆ†æ•¸ (Confidence Score)ã€‚
"""

import streamlit as st
import os
import nest_asyncio
from llama_index.core import StorageContext, load_index_from_storage, Settings
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding

# --- Import è·¯å¾‘ä¿®æ­£èˆ‡æ¨¡çµ„ä¾è³´ ---
# å¼•å…¥æ ¸å¿ƒæª¢ç´¢å™¨ä»‹é¢èˆ‡å¯¦ä½œ
from llama_index.core.retrievers import VectorIndexRetriever, BaseRetriever
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core import PromptTemplate

# è§£æ±ºç•°æ­¥ (AsyncIO) åœ¨ Streamlit ç’°å¢ƒä¸‹çš„äº‹ä»¶è¿´åœˆè¡çªå•é¡Œ
nest_asyncio.apply()

# --- Streamlit é é¢çµ„æ…‹è¨­å®š ---
st.set_page_config(page_title="å°ç©é›»å¹´å ± AI åŠ©æ‰‹", layout="wide")
st.title("ğŸ¤– TSMC å¹´å ± RAG åŠ©æ‰‹ (Gemini 2.5 + Hybrid Search)")

# --- å´é‚Šæ¬„é…ç½® (Sidebar Configuration) ---
# è² è²¬è™•ç†ç’°å¢ƒè®Šæ•¸èˆ‡ API Key çš„è¼¸å…¥ï¼Œç¢ºä¿æ‡‰ç”¨ç¨‹å¼å®‰å…¨æ€§
with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    
    # å˜—è©¦é å…ˆè®€å–ç’°å¢ƒè®Šæ•¸ï¼Œä»¥æå‡é–‹ç™¼è€…é«”é©— (DX)
    default_key = os.environ.get("GOOGLE_API_KEY", "")
    api_key = st.text_input("Google API Key", value=default_key, type="password")
    
    # è‹¥ä½¿ç”¨è€…æœ‰è¼¸å…¥ Keyï¼Œå‰‡æ›´æ–°ç’°å¢ƒè®Šæ•¸
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
    
    st.divider()
    st.info("ç³»çµ±æç¤ºï¼šè«‹ç¢ºä¿ ./storage æŒä¹…åŒ–ç›®éŒ„å·²å»ºç«‹ (éœ€é å…ˆåŸ·è¡Œ Data Ingestion Pipeline)ã€‚")
    if st.button("ğŸ”„ é‡æ–°è¼‰å…¥æ‡‰ç”¨ç¨‹å¼"):
        st.rerun()

# --- å…ˆæ±ºæ¢ä»¶æª¢æŸ¥ (Pre-flight Check) ---
# å¼·åˆ¶è¦æ±‚ API Key å­˜åœ¨ï¼Œå¦å‰‡é˜»æ–·åŸ·è¡Œæµç¨‹ (Circuit Breaker)
if not os.environ.get("GOOGLE_API_KEY"):
    st.warning("â¬…ï¸ è«‹å…ˆæ–¼å´é‚Šæ¬„è¨­å®š Google API Key ä»¥åˆå§‹åŒ– LLM æœå‹™ã€‚")
    st.stop()
# --------------------

# --- æ ¸å¿ƒé¡åˆ¥å®šç¾© (Core Definitions) ---

class CustomHybridRetriever(BaseRetriever):
    """
    è‡ªå®šç¾©æ··åˆæª¢ç´¢å™¨ (Custom Hybrid Retriever)
    
    å¯¦ä½œ RAG çš„æ··åˆæª¢ç´¢ç­–ç•¥ï¼Œçµåˆå‘é‡æª¢ç´¢ (Vector Search) èˆ‡é—œéµå­—æª¢ç´¢ (BM25)ã€‚
    
    Attributes:
        vector_retriever (VectorIndexRetriever): è² è²¬èªæ„ç›¸ä¼¼åº¦æª¢ç´¢ (Semantic Similarity)ã€‚
        bm25_retriever (BM25Retriever): è² è²¬é—œéµå­—ç²¾æº–åŒ¹é… (Exact Keyword Match)ã€‚
    """
    
    def __init__(self, vector_retriever, bm25_retriever):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        super().__init__()

    def _retrieve(self, query_bundle):
        """
        åŸ·è¡Œæª¢ç´¢é‚è¼¯ï¼Œä¸¦åˆä½µ(Merge)èˆ‡å»é‡(Deduplicate)å…©ç¨®æª¢ç´¢å™¨çš„çµæœã€‚
        
        Args:
            query_bundle (QueryBundle): åŒ…å«æŸ¥è©¢å­—ä¸²èˆ‡ç›¸é—œè³‡è¨Šçš„ç‰©ä»¶ã€‚
            
        Returns:
            List[NodeWithScore]: åˆä½µå¾Œçš„æª¢ç´¢ç¯€é»åˆ—è¡¨ã€‚
        """
        try:
            # 1. å¹³è¡ŒåŸ·è¡Œå…©ç¨®æª¢ç´¢ç­–ç•¥
            vec_nodes = self.vector_retriever.retrieve(query_bundle)
            bm25_nodes = self.bm25_retriever.retrieve(query_bundle)
            
            # 2. çµæœåˆä½µç­–ç•¥ (Merge Strategy)
            # ä½¿ç”¨ Dictionary ä»¥ node_id ç‚ºéµé€²è¡Œå»é‡ï¼Œå„ªå…ˆä¿ç•™å‘é‡æª¢ç´¢çµæœ
            all_nodes = {}
            for node in vec_nodes: 
                all_nodes[node.node.node_id] = node
            for node in bm25_nodes:
                if node.node.node_id not in all_nodes: 
                    all_nodes[node.node.node_id] = node
            
            # 3. å›å‚³å‰ 20 ç­†æœ€ç›¸é—œçš„çµæœ (Top-K)
            return list(all_nodes.values())[:20]
        except Exception as e:
            # éŒ¯èª¤è™•ç†ï¼šè¨˜éŒ„éŒ¯èª¤ä¸¦å›å‚³ç©ºåˆ—è¡¨ä»¥é¿å… Crash
            print(f"Retrieval Error: {e}")
            return []

# --- ä¾è³´æ³¨å…¥èˆ‡è³‡æºåˆå§‹åŒ– (Dependency Injection & Initialization) ---

@st.cache_resource
def load_rag_engine():
    """
    åˆå§‹åŒ–ä¸¦è¼‰å…¥ RAG æŸ¥è©¢å¼•æ“ (Query Engine)ã€‚
    
    ä½¿ç”¨ @st.cache_resource è£é£¾å™¨å¯¦ç¾ Singleton æ¨¡å¼ï¼Œ
    ç¢ºä¿åœ¨ Streamlit çš„å¤šæ¬¡äº’å‹•ä¸­ï¼Œæ¨¡å‹èˆ‡ç´¢å¼•åªæœƒè¢«è¼‰å…¥ä¸€æ¬¡ï¼Œå„ªåŒ–æ•ˆèƒ½ã€‚
    
    Returns:
        RetrieverQueryEngine: åˆå§‹åŒ–å®Œæˆçš„æŸ¥è©¢å¼•æ“å¯¦ä¾‹ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³ Noneã€‚
    """
    persist_dir = "./storage"
    
    # æª¢æŸ¥æŒä¹…åŒ–å„²å­˜å±¤æ˜¯å¦å­˜åœ¨
    if not os.path.exists(persist_dir):
        return None
    
    try:
        # è¨­å®š LLM èˆ‡ Embedding æ¨¡å‹ (Global Settings Configuration)
        Settings.llm = Gemini(model="models/gemini-2.5-flash", api_key=os.environ["GOOGLE_API_KEY"])
        Settings.embed_model = GeminiEmbedding(model_name="models/text-embedding-004", api_key=os.environ["GOOGLE_API_KEY"])
        
        # å¾ç£ç¢Ÿè¼‰å…¥ç´¢å¼•çµæ§‹ (Load Index from Disk)
        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)
        index = load_index_from_storage(storage_context)
        
        # å¯¦ä¾‹åŒ–æª¢ç´¢å™¨å…ƒä»¶ (Instantiate Retrievers)
        vector_retriever = VectorIndexRetriever(index=index, similarity_top_k=10)
        bm25_retriever = BM25Retriever.from_defaults(docstore=index.docstore, similarity_top_k=10)
        
        # ä¾è³´æ³¨å…¥ï¼šçµ„åˆæ··åˆæª¢ç´¢å™¨
        retriever = CustomHybridRetriever(vector_retriever, bm25_retriever)
        
        # å®šç¾©ç³»çµ±æç¤ºè© (System Prompt Construction)
        # å¼·èª¿ã€ŒåŸºæ–¼äº‹å¯¦ã€(Grounding) èˆ‡ç¹é«”ä¸­æ–‡è¼¸å‡ºçš„è¦ç¯„
        qa_prompt_str = (
            "ä»¥ä¸‹æ˜¯åƒè€ƒæ–‡ä»¶å…§å®¹ï¼š\n---------------------\n{context_str}\n---------------------\n"
            "è«‹åƒ…æ ¹æ“šä¸Šè¿°åƒè€ƒæ–‡ä»¶å…§å®¹ï¼Œå›ç­”ä½¿ç”¨è€…çš„å•é¡Œ: {query_str}\n"
            "åš´æ ¼ç¦æ­¢ç·¨é€ æ–‡ä»¶ä¸­æœªæåŠçš„äººåã€æ•¸å­—æˆ–è·ç¨± (Hallucination Prevention)ã€‚\n"
            "è«‹å‹™å¿…ä½¿ç”¨ã€Œç¹é«”ä¸­æ–‡ã€å›ç­”ï¼Œè‹¥æ˜¯è¡¨æ ¼æ•¸æ“šè«‹æ’ç‰ˆæ•´é½Šã€‚\n"
        )
        
        # æ§‹å»ºæœ€çµ‚æŸ¥è©¢å¼•æ“
        return RetrieverQueryEngine.from_args(
            retriever=retriever,
            text_qa_template=PromptTemplate(qa_prompt_str)
        )
    except Exception as e:
        st.error(f"å¼•æ“åˆå§‹åŒ–å¤±æ•— (Initialization Failed): {e}")
        return None

# --- ä¸»æ‡‰ç”¨ç¨‹å¼é‚è¼¯ (Main Application Logic) ---

# åˆå§‹åŒ–å°è©±æ­·å²ç‹€æ…‹ (Session State Management)
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ¸²æŸ“æ­·å²å°è©±è¨Šæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è¼‰å…¥æ ¸å¿ƒå¼•æ“
engine = load_rag_engine()

if engine is None:
    st.error("âŒ ç³»çµ±éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° ./storage ç´¢å¼•ç›®éŒ„ã€‚è«‹ç¢ºä¿å·²åŸ·è¡Œ ETL Pipeline (`python rag_engine.py`) ç”Ÿæˆç´¢å¼•ã€‚")
else:
    # è™•ç†ä½¿ç”¨è€…è¼¸å…¥äº‹ä»¶
    if prompt := st.chat_input("è«‹è¼¸å…¥å•é¡Œ (ä¾‹å¦‚ï¼šè‘£äº‹æœƒæˆå“¡æœ‰å“ªäº›ï¼Ÿ)"):
        # æ›´æ–° UI ä¸¦è¨˜éŒ„ä½¿ç”¨è€…è¨Šæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # è§¸ç™¼ AI å›æ‡‰æµç¨‹
        with st.chat_message("assistant"):
            with st.spinner("AI æ­£åœ¨é€²è¡Œèªæ„æª¢ç´¢èˆ‡ç”Ÿæˆ (RAG Processing)..."):
                try:
                    # åŸ·è¡ŒæŸ¥è©¢
                    response = engine.query(prompt)
                    st.markdown(response.response)
                    
                    # ä½¿ç”¨ Expander å±•ç¤ºå¯è§£é‡‹æ€§è³‡è¨Š (Explainability)
                    with st.expander("ğŸ•µï¸ åƒè€ƒä¾†æºç‰‡æ®µ (Source Context)"):
                        for node in response.source_nodes:
                            score = f"{node.score:.2f}" if node.score is not None else "Hybrid"
                            st.caption(f"**[é—œè¯åˆ†æ•¸ {score}]**")
                            st.text(node.node.get_text()[:200] + "...")
                            st.divider()

                    # è¨˜éŒ„ AI å›æ‡‰è‡³ Session State
                    st.session_state.messages.append({"role": "assistant", "content": response.response})
                
                except Exception as e:
                    st.error(f"åŸ·è¡Œéšæ®µéŒ¯èª¤ (Runtime Error): {e}")